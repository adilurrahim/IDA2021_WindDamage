# Repository Structure

This document describes the organization of the Hurricane Ida Wind Loss Analysis Pipeline.

## File Overview

```
github_publication/
├── main_pipeline.py          # Main pipeline orchestrator with CLI
├── config.py                  # Configuration constants and parameters
├── requirements.txt           # Python package dependencies
├── README.md                  # Complete documentation
├── .gitignore                 # Git ignore rules
├── STRUCTURE.md              # This file
└── modules/                   # Pipeline processing modules
    ├── __init__.py           # Module package initialization
    ├── netcdf_processor.py   # Step 1: NetCDF processing
    ├── spatial_join.py       # Step 2: Spatial join
    └── building_losses.py    # Step 3: Loss calculation
```

## Module Descriptions

### `main_pipeline.py`
Main entry point for the pipeline. Handles:
- Command-line argument parsing (argparse)
- Input validation and error reporting
- Pipeline orchestration and step execution
- Logging setup (console + file)
- Progress tracking and summary reporting

### `config.py`
Central configuration file containing:
- Physical constants (gust factors, unit conversions)
- Hazus damage function parameters
- Climate scenario definitions
- Coordinate reference systems
- File naming conventions
- All configuration in one place for easy modification

### `modules/netcdf_processor.py`
**Step 1: NCAR NetCDF Processing**
- Processes NCAR climate model NetCDF files
- Extracts wind swath data (swath_wind, lon_2d, lat_2d)
- Converts to gust wind speeds (ASCE 7-16 standard)
- Converts units (m/s to mph)
- Adjusts longitude coordinates
- Outputs processed CSV files

### `modules/spatial_join.py`
**Step 2: Spatial Join**
- Loads NSI building inventory (GeoPackage)
- Loads processed wind data (CSV → GeoDataFrame)
- Projects to NAD83 / UTM zone 15N for accurate distances
- Performs nearest neighbor spatial join
- Assigns wind speeds to each building
- Logs distance statistics for quality assessment

### `modules/building_losses.py`
**Step 3: Loss Calculation (3 sub-steps)**

**Step 3A: Building Characterization** (`characterize_buildings`)
- Maps NSI buildings to Hazus building types
- Probabilistic assignment using county-specific schemes
- Calculates terrain IDs from surface roughness
- **Includes checkpointing** (~30-60 min first run, seconds thereafter)

**Step 3B: Individual Building Losses** (`calculate_building_losses`)
- Looks up Hazus damage functions by building type
- Interpolates loss ratios from wind speeds
- Calculates dollar losses for each building
- Processes all three climate scenarios

**Step 3C: County-Level Aggregation** (`aggregate_county_losses`)
- Aggregates individual losses to county level
- Creates summary table comparing scenarios
- Outputs final results (TotalLoss.csv)

## Data Flow

```
NCAR NetCDF files (ida_YYYY.nc)
    ↓
[Step 1: NetCDF Processing]
    ↓
Wind CSV files (ida_YYYY.csv)
    ↓                           NSI Building Inventory (.gpkg)
    └─────────→ [Step 2: Spatial Join] ←─────────┘
                        ↓
                Joined CSV files (buildings + wind speeds)
                        ↓                           Hazus Files (.xlsx, .csv)
                [Step 3A: Characterization] ←───────────┘
                        ↓
                Building Inventory (with wbID, terrainID)
                        ↓
                [Step 3B: Loss Calculation]
                        ↓
                Individual Building Losses (Losses.csv)
                        ↓
                [Step 3C: County Aggregation]
                        ↓
                Total Loss Summary (TotalLoss.csv)
```

## Expected Directory Structure After Setup

Users should organize their data and outputs as follows:

```
project_root/
├── main_pipeline.py
├── config.py
├── requirements.txt
├── README.md
├── modules/
│   ├── __init__.py
│   ├── netcdf_processor.py
│   ├── spatial_join.py
│   └── building_losses.py
├── data/                      # User provides (not in repo)
│   ├── ncar_netcdf/
│   │   ├── ida_1971.nc
│   │   ├── ida_2021.nc
│   │   └── ida_2071.nc
│   ├── nsi/
│   │   └── nsi_2022_22.gpkg
│   └── hazus/
│       ├── Mapping.xlsx
│       └── huDamLossFunc.csv
├── output/                    # Generated by pipeline (not in repo)
│   ├── processed_wind/
│   ├── building_inventory/
│   ├── joined_data/
│   └── results/
└── logs/                      # Generated by pipeline (not in repo)
    └── pipeline_*.log
```

## Key Features

### Checkpointing
The building characterization step (Step 3A) is computationally expensive. Results are automatically saved to:
```
output/building_inventory/nsi_wbId_sr.csv
```
On subsequent runs, this checkpoint is loaded instead of recomputing (~seconds vs. ~30-60 minutes).

### Logging
All execution is logged to:
- **Console**: Real-time progress updates
- **File**: `logs/pipeline_YYYYMMDD_HHMMSS.log`

Logs include:
- Input validation results
- Processing progress
- Statistics and summaries
- Warnings and errors
- Execution times

### Error Handling
- Validates all inputs before processing
- Clear error messages when data files missing
- Logs all errors to file
- Graceful failure with helpful guidance

### Reproducibility
- Fixed random seed (121) for probabilistic assignments
- All configuration in central config.py
- Documented methodology in README.md
- Comprehensive logging of all operations

## For Developers

### Adding a New Processing Step

1. Create new module in `modules/` directory
2. Import in `modules/__init__.py`
3. Add function call in `main_pipeline.py` run_pipeline()
4. Update README.md with new step documentation
5. Add any new constants to `config.py`

### Modifying Configuration

All configuration parameters are centralized in `config.py`:
- Physical constants
- File naming conventions
- Scenario definitions
- Coordinate systems
- etc.

Modify config.py rather than hardcoding values in modules.

### Testing

To test individual modules:

```python
# Test NetCDF processor
from modules import netcdf_processor
wind_csvs = netcdf_processor.process_ncar_netcdf(
    ncar_dir='./data/ncar_netcdf',
    output_dir='./output/processed_wind'
)
```

### Code Style

- Comprehensive docstrings (NumPy style)
- Type hints in function signatures where appropriate
- Descriptive variable names
- Logging at INFO level for major operations
- Error logging at ERROR level
- Clear separation of concerns (one function = one task)

## Publication Checklist

Before submitting code with manuscript:

- [ ] All paths are configurable (no hardcoded paths)
- [ ] README.md is complete and accurate
- [ ] requirements.txt lists all dependencies
- [ ] Code is well-documented with docstrings
- [ ] Example data or data access instructions provided
- [ ] .gitignore excludes large data files
- [ ] License file included
- [ ] Citation information added to README.md
- [ ] Contact information added to README.md
- [ ] Tested on clean environment (fresh install)

## Support

For questions or issues:
1. Check README.md documentation
2. Review log files in `logs/` directory
3. Check STRUCTURE.md (this file) for architecture
4. Open GitHub issue with:
   - Log file contents
   - Command used
   - Error message
   - Python version and OS
